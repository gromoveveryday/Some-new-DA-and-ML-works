{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n",
    "from sklearn.metrics import roc_auc_score, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel(r'Z:\\DATASETS\\otp\\test.xls')\n",
    "train = pd.read_excel(r'Z:\\DATASETS\\otp\\train.xls')\n",
    "y_train = train['TARGET']\n",
    "y_test = pd.read_excel(r'Z:\\DATASETS\\otp\\submission.xls')\n",
    "test = pd.concat([test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:43:10] Stdout logging level is INFO.\n",
      "[17:43:10] Task: binary\n",
      "\n",
      "[17:43:10] Start automl preset with listed constraints:\n",
      "[17:43:10] - time: 300.00 seconds\n",
      "[17:43:10] - CPU: 4 cores\n",
      "[17:43:10] - memory: 16 GB\n",
      "\n",
      "[17:43:10] \u001b[1mTrain data shape: (15223, 52)\u001b[0m\n",
      "\n",
      "[17:43:11] Layer \u001b[1m1\u001b[0m train process start. Time left 299.07 secs\n",
      "[17:43:12] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[17:43:15] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.6887462690424304\u001b[0m\n",
      "[17:43:15] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:43:15] Time left 295.17 secs\n",
      "\n",
      "[17:43:15] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:43:15] \u001b[1mAutoml preset training completed in 4.84 seconds\u001b[0m\n",
      "\n",
      "[17:43:15] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (3 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) \n",
      "\n",
      "\n",
      "Test AUC score: 0.6951\n"
     ]
    }
   ],
   "source": [
    "task1 = Task('binary', metric='auc') # Задача - бинарная классификация (10 лабораторная)\n",
    "\n",
    "automl1 = TabularAutoML( # Настройки LightAutoML для логистической регрессии\n",
    "    task=task1,\n",
    "    timeout=300,  # 300 секунд\n",
    "    cpu_limit=4, # у меня от 4 до 8 ядер\n",
    "    general_params={'use_algos': [['linear_l2']]},  # Используем только линейные модели\n",
    "    reader_params={'n_jobs': 4, 'cv': 3, 'random_state': 42}\n",
    ")\n",
    "\n",
    "roles = {'target': 'TARGET'} # Определение ролей переменных\n",
    "\n",
    "oof_pred = automl1.fit_predict( # Обучение модели (правильный вызов fit_predict)\n",
    "    train_data=train,\n",
    "    roles=roles,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "X_test = test.drop('TARGET', axis=1) # Подготовка  данных (без целевой переменной)\n",
    "y_test = test['TARGET']\n",
    "\n",
    "test_pred = automl1.predict(X_test) # Предсказание на тестовых данных\n",
    "\n",
    "auc_score = roc_auc_score(y_test, test_pred.data[:, 0]) # Оценка модели\n",
    "print(f\"\\nTest AUC score: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:11:45] Stdout logging level is INFO.\n",
      "[18:11:45] Task: reg\n",
      "\n",
      "[18:11:45] Start automl preset with listed constraints:\n",
      "[18:11:45] - time: 600.00 seconds\n",
      "[18:11:45] - CPU: 4 cores\n",
      "[18:11:45] - memory: 16 GB\n",
      "\n",
      "[18:11:45] \u001b[1mTrain data shape: (369456, 15)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Илья\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightautoml\\dataset\\np_pd_dataset.py:590: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.data[i] = pd.to_datetime(\n",
      "C:\\Users\\Илья\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightautoml\\dataset\\np_pd_dataset.py:590: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.data[i] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:12:26] Layer \u001b[1m1\u001b[0m train process start. Time left 559.02 secs\n",
      "[18:12:45] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[18:12:50] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m-0.30991482734680176\u001b[0m\n",
      "[18:12:50] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[18:12:50] Time left 535.07 secs\n",
      "\n",
      "[18:12:54] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:13:21] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[18:14:12] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.44658273458480835\u001b[0m\n",
      "[18:14:12] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:14:12] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 94.17 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  10%|▉         | 10/101 [01:45<15:58, 10.53s/it, best_trial=8, best_value=0.447]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:15:57] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[18:15:57] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:16:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.45220017433166504\u001b[0m\n",
      "[18:16:43] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[18:16:43] Time left 302.22 secs\n",
      "\n",
      "[18:16:43] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[18:16:43] Blending: optimization starts with equal weights. Score = \u001b[1m0.3690357\u001b[0m\n",
      "[18:16:43] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.4533717\u001b[0m, weights = \u001b[1m[0.         0.29349294 0.706507  ]\u001b[0m\n",
      "[18:16:43] Blending: no improvements for score. Terminated.\n",
      "\n",
      "[18:16:43] Blending: best score = \u001b[1m0.4533717\u001b[0m, best weights = \u001b[1m[0.         0.29349294 0.706507  ]\u001b[0m\n",
      "[18:16:43] \u001b[1mAutoml preset training completed in 298.49 seconds\u001b[0m\n",
      "\n",
      "[18:16:43] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.29349 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.70651 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Илья\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\lightautoml\\dataset\\np_pd_dataset.py:590: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  self.data[i] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "R2 score: 0.8502\n",
      "MAPE: 0.5209\n"
     ]
    }
   ],
   "source": [
    "# Для задачи регресии по недвижимости \n",
    "\n",
    "df2 = pd.read_csv(r'Z:\\DATASETS\\all_v2.csv')\n",
    "\n",
    "df2 = df2[(df2['region'] == 2661)] # Единственное условие\n",
    "\n",
    "train, test = train_test_split(df2, test_size=0.2, random_state=42)\n",
    "\n",
    "train['date_difference'] = (pd.to_datetime(train['date'].max()) - pd.to_datetime(train['date'])).dt.days\n",
    "test['date_difference'] = (pd.to_datetime(test['date'].max()) - pd.to_datetime(test['date'])).dt.days\n",
    "\n",
    "target_point = (59.938962, 30.315586)  # Центр СПБ\n",
    "\n",
    "def calculate_distance(row, target):\n",
    "    point = (row['geo_lat'], row['geo_lon'])\n",
    "    return geodesic(point, target).kilometers\n",
    "\n",
    "train['distance_to_the_center_km'] = train.apply(calculate_distance, target=target_point, axis=1)\n",
    "\n",
    "def calculate_distance(row, target):\n",
    "    point = (row['geo_lat'], row['geo_lon'])\n",
    "    return geodesic(point, target).kilometers\n",
    "\n",
    "test['distance_to_the_center_km'] = test.apply(calculate_distance, target=target_point, axis=1)\n",
    "\n",
    "# Определение задачи как регрессии\n",
    "task2 = Task('reg', metric='r2')  # Можно также использовать 'mae', 'mse', 'rmse'\n",
    "\n",
    "automl = TabularAutoML( # Настройки LightAutoML для регрессии\n",
    "    task=task2,\n",
    "    timeout=600,  # 10 минут на обучение\n",
    "    cpu_limit=4, # \n",
    "    general_params={'use_algos': [['linear_l2', 'lgb', 'lgb_tuned']]},  # Линейные модели + LightGBM\n",
    "    reader_params={'n_jobs': 4, 'cv': 5, 'random_state': 42}\n",
    ")\n",
    "\n",
    "roles = {'target': 'price', 'drop': []}  # Определение ролей переменных\n",
    "\n",
    "oof_pred = automl.fit_predict( # Обучение модели\n",
    "    train_data=train,\n",
    "    roles=roles,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "X_test = test.drop('price', axis=1) # Подготовка тестовых данных\n",
    "y_test = test['price']\n",
    "\n",
    "# Предсказание на тестовых данных\n",
    "test_pred = automl.predict(X_test)\n",
    "\n",
    "# Оценка модели\n",
    "r2 = r2_score(y_test, test_pred.data)\n",
    "mape = mean_absolute_percentage_error(y_test, test_pred.data)\n",
    "\n",
    "print(f\"\\nR2 score: {r2:.4f}\")\n",
    "print(f\"MAPE: {mape:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
